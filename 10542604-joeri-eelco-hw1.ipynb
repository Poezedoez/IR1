{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical part\n",
    "1. hoe werkt markdown en doe ik linebreaks\n",
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math, random, itertools, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs: 59049\n",
      "first 10 pairs:\n"
     ]
    }
   ],
   "source": [
    "def pair_generator():\n",
    "    \"\"\"\n",
    "    A generator that returns pairs of all possible combinations \n",
    "    of [N, R, HR] of length 5, with repeated elements.\n",
    "    \"\"\"\n",
    "    for p in itertools.product(itertools.product(['N', 'R', 'HR'], repeat=5), repeat=2):\n",
    "        yield p\n",
    "\n",
    "print('Number of pairs:', len(list(pair_generator())))\n",
    "\n",
    "print('first 10 pairs:')\n",
    "pair_gen = pair_generator()\n",
    "for _ in range(10000):\n",
    "    next(pair_gen)\n",
    "\n",
    "def random_sample(length):\n",
    "    '''\n",
    "    Returns a sample pair that\n",
    "    consists of a production and \n",
    "    an experiment list, with as possible\n",
    "    values {N, R, HR}.\n",
    "    '''\n",
    "    values = ['N', 'R', 'HR']\n",
    "    \n",
    "    p = [values[random.randint(0, 2)] for _ in range(length)]\n",
    "    e = [values[random.randint(0, 2)] for _ in range(length)]\n",
    "    \n",
    "    return p, e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of production algorithm:\t 0.6\n",
      "Precision of experimental algorithm:\t 0.8\n",
      "EER of production algorithm:\t\t 0.2333333333333333\n",
      "EER of experimental algorithm:\t\t 0.83515625\n",
      "NDCG of production algorithm:\t\t 0.217888248145\n",
      "NDCG of experimental algorithm:\t\t 0.629148817528\n"
     ]
    }
   ],
   "source": [
    "# Implement Evaluation Measures\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def binary_precision(p, f=None):\n",
    "    return np.array([0 if x == 'N' else 1 for x in p]).sum() / len(p)\n",
    "\n",
    "def ndcg(p, relevance_map):\n",
    "    dcg = np.array([\n",
    "        (2 ** relevance_map[x] - 1) / np.log2(r + 1) for r, x in enumerate(p, start=1) \n",
    "    ])\n",
    "\n",
    "    return (dcg / (max(relevance_map.values()) * len(p))).sum() if dcg.max() != 0 else 0\n",
    "\n",
    "def err(p, relevance_map):\n",
    "    P = 1\n",
    "    E = 0\n",
    "    for r, v in enumerate(p, start=1):\n",
    "        R = (2 ** relevance_map[v] - 1) / (2 ** max(relevance_map.values()))\n",
    "        E += P * R / r\n",
    "        P *= (1-R)\n",
    "    return E\n",
    "    \n",
    "p, e = random_sample(5)\n",
    "\n",
    "relevance_map = {\n",
    "    'N': 0,\n",
    "    'R': 1,\n",
    "    'HR': 2\n",
    "}\n",
    "\n",
    "print('Precision of production algorithm:\\t', binary_precision(p))\n",
    "print('Precision of experimental algorithm:\\t', binary_precision(e))\n",
    "\n",
    "print('EER of production algorithm:\\t\\t', err(p, relevance_map))\n",
    "print('EER of experimental algorithm:\\t\\t', err(e, relevance_map))\n",
    "\n",
    "print('NDCG of production algorithm:\\t\\t', ndcg(p, relevance_map))\n",
    "print('NDCG of experimental algorithm:\\t\\t', ndcg(e, relevance_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of ndcg delta for each pair where E outperforms P 0.200319926403\n",
      "Average of err delta for each pair where E outperforms P 0.2683316783196332\n",
      "Average of binary_precision delta for each pair where E outperforms P 0.316516197557\n"
     ]
    }
   ],
   "source": [
    "def delta(data, eval_function, relevance_map):\n",
    "    return [(x, y, eval_function(x, relevance_map) - eval_function(y, relevance_map))\n",
    "            for x, y in data]\n",
    "\n",
    "data = [random_sample(5) for _ in range(5000)]\n",
    "\n",
    "filtered_data = [x for x in delta(data, ndcg, relevance_map) if x[2] > 0]\n",
    "print('Average of ndcg delta for each pair where E outperforms P', \n",
    "      sum([x[2] for x in filtered_data]) / len(filtered_data))\n",
    "\n",
    "filtered_data = [x for x in delta(data, err, relevance_map) if x[2] > 0]\n",
    "print('Average of err delta for each pair where E outperforms P', \n",
    "      sum([x[2] for x in filtered_data]) / len(filtered_data))\n",
    "\n",
    "filtered_data = [x for x in delta(data, binary_precision, relevance_map) if x[2] > 0]\n",
    "print('Average of binary_precision delta for each pair where E outperforms P', \n",
    "      sum([x[2] for x in filtered_data]) / len(filtered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3} {5, 6, 7, 8, 9}\n",
      "[0, 1, 2, 3, 4] [5, 6, 7, 8, 9]\n",
      "[5, 0, 1, 6, 7, 2, 8, 3, 9]\n"
     ]
    }
   ],
   "source": [
    "def teamdraft_interleaving(docs1, docs2):\n",
    "    team_a = set()\n",
    "    team_b = set()\n",
    "    i = []\n",
    "    \n",
    "    while len(set(docs1) - set(i)) > 0 and len(set(docs2) - set(i)):\n",
    "        if len(team_a) < len(team_b) or (len(team_a) == len(team_b) and random.random() > 0.5):\n",
    "            k = [x for x in docs1 if not x in i][0]\n",
    "            i.append(k)\n",
    "            team_a.add(k)\n",
    "        else:\n",
    "            k = [x for x in docs2 if not x in i][0]\n",
    "            i.append(k)\n",
    "            team_b.add(k)\n",
    "    return i, team_a, team_b\n",
    "\n",
    "docs1, docs2 = ['a', 'b', 'c', 'd'], ['b', 'c', 'd', 'a' ]\n",
    "p, e = random_sample(5)\n",
    "p_n = [x for x in range(len(p))]\n",
    "e_n = [x + len(p) for x in range(len(p))]\n",
    "\n",
    "i, a, b = teamdraft_interleaving(p_n, e_n)\n",
    "labels_i = [(p+e)[vis] for vis in i]\n",
    "\n",
    "print(a, b)\n",
    "print(p_n, e_n)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.576893042361473"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sessions from Yandex file...\n",
      "Number of sessions: 42652\n"
     ]
    }
   ],
   "source": [
    "def load_yandex(filename):\n",
    "    sessions = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        data = [line.strip().split('\\t') for  line in f.readlines()]\n",
    "    for i, query_line in enumerate(data):\n",
    "        # Q indicates start of a session\n",
    "        if query_line[2] != \"Q\":\n",
    "            continue\n",
    "\n",
    "        url_ids = query_line[5:]\n",
    "\n",
    "        # Get url_ids of all subsequent lines that are clicks\n",
    "        clicks = np.zeros(len(url_ids))\n",
    "        for click_line in data[i+1:]:\n",
    "            if click_line[2] == \"C\":\n",
    "                click_url = click_line[3]\n",
    "                if click_url not in url_ids:\n",
    "                    continue\n",
    "                clicks[url_ids.index(click_url)] = 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            sessions.append(clicks)\n",
    "    return np.vstack(sessions)\n",
    "\n",
    "print('Loading sessions from Yandex file...')\n",
    "sessions = load_yandex('YandexRelPredChallenge.txt')\n",
    "print('Number of sessions:', len(sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45006096  0.1950905   0.13931351  0.10569258  0.08184845  0.06712464\n",
      "  0.05936416  0.05296352  0.04808684  0.05071275]\n",
      "0.125025790115\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def calc_rel_prob(label, relevance_map):\n",
    "    return 2 ** relevance_map[label] / 2 ** max(relevance_map.values())\n",
    "\n",
    "\n",
    "class PBM(object):\n",
    "    def __init__(self, ranking_size):\n",
    "        self.alpha = defaultdict(lambda: 1)\n",
    "        self.gamma = [random.random() for _ in range(ranking_size)]\n",
    "        \n",
    "    def estimate(self, S):\n",
    "        self.gamma = S.sum(axis=0) / len(S)\n",
    "    \n",
    "    def predict(self, ranking, query):\n",
    "        return [g * self.alpha[(u, query)] for g, u in zip(self.gamma, ranking)]\n",
    "           \n",
    "    def simulate():\n",
    "        return something\n",
    "\n",
    "class RCM:\n",
    "    def _init_(self):\n",
    "        self.rho = 0\n",
    "        \n",
    "    def estimate(self, S):\n",
    "        self.rho = sum(sum(s) for s in S) / sum(len(s) for s in S)\n",
    "        \n",
    "    def predict(self, ranking):\n",
    "        probs = [self.rho] * len(ranking)\n",
    "        return probs\n",
    "            \n",
    "    def simulate(self, ranking):\n",
    "        probs = self.predict(ranking)\n",
    "        for i, (page, prob) in enumerate(zip(ranking, probs)):\n",
    "            if np.random.random() < prob:\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "S = np.array(\n",
    "    [[1, 0, 0, 0, 0], \n",
    "     [0, 1, 0, 0, 0], \n",
    "     [0, 0, 1, 0, 0], \n",
    "     [0, 0, 0, 1, 0], \n",
    "     [0, 0, 0, 0, 1], \n",
    "     [1, 0, 0, 0, 0]]\n",
    ")\n",
    "\n",
    "pbm_model = PBM(sessions.shape[1])\n",
    "pbm_model.estimate(sessions)\n",
    "print(pbm_model.gamma)\n",
    "\n",
    "rcm_model = RCM()\n",
    "rcm_model.estimate(sessions)\n",
    "print(rcm_model.rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
