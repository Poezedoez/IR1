{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical part\n",
    "1. hoe werkt markdown en doe ik linebreaks\n",
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math, random, itertools, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs: 59049\n",
      "first 10 pairs:\n"
     ]
    }
   ],
   "source": [
    "def pair_generator():\n",
    "    \"\"\"\n",
    "    A generator that returns pairs of all possible combinations \n",
    "    of [N, R, HR] of length 5, with repeated elements.\n",
    "    \"\"\"\n",
    "    for p in itertools.product(itertools.product(['N', 'R', 'HR'], repeat=5), repeat=2):\n",
    "        yield p\n",
    "\n",
    "print('Number of pairs:', len(list(pair_generator())))\n",
    "\n",
    "print('first 10 pairs:')\n",
    "pair_gen = pair_generator()\n",
    "for _ in range(10000):\n",
    "    next(pair_gen)\n",
    "\n",
    "def random_sample(length):\n",
    "    '''\n",
    "    Returns a sample pair that\n",
    "    consists of a production and \n",
    "    an experiment list, with as possible\n",
    "    values {N, R, HR}.\n",
    "    '''\n",
    "    values = ['N', 'R', 'HR']\n",
    "    \n",
    "    p = [values[random.randint(0, 2)] for _ in range(length)]\n",
    "    e = [values[random.randint(0, 2)] for _ in range(length)]\n",
    "    \n",
    "    return p, e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of production algorithm:\t 0.8\n",
      "Precision of experimental algorithm:\t 0.8\n",
      "EER of production algorithm:\t\t 0.5734375\n",
      "EER of experimental algorithm:\t\t 0.58515625\n",
      "NDCG of production algorithm:\t\t 0.534537735664\n",
      "NDCG of experimental algorithm:\t\t 0.555334768242\n"
     ]
    }
   ],
   "source": [
    "# Implement Evaluation Measures\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def binary_precision(p, f=None):\n",
    "    return np.array([0 if x == 'N' else 1 for x in p]).sum() / len(p)\n",
    "\n",
    "def ndcg(p, relevance_map):\n",
    "    dcg = np.array([\n",
    "        (2 ** relevance_map[x] - 1) / np.log2(r + 1) for r, x in enumerate(p, start=1) \n",
    "    ])\n",
    "\n",
    "    return (dcg / (max(relevance_map.values()) * len(p))).sum() if dcg.max() != 0 else 0\n",
    "\n",
    "def err(p, relevance_map):\n",
    "    P = 1\n",
    "    E = 0\n",
    "    for r, v in enumerate(p, start=1):\n",
    "        R = (2 ** relevance_map[v] - 1) / (2 ** max(relevance_map.values()))\n",
    "        E += P * R / r\n",
    "        P *= (1-R)\n",
    "    return E\n",
    "    \n",
    "p, e = random_sample(5)\n",
    "\n",
    "relevance_map = {\n",
    "    'N': 0,\n",
    "    'R': 1,\n",
    "    'HR': 2\n",
    "}\n",
    "\n",
    "print('Precision of production algorithm:\\t', binary_precision(p))\n",
    "print('Precision of experimental algorithm:\\t', binary_precision(e))\n",
    "\n",
    "print('EER of production algorithm:\\t\\t', err(p, relevance_map))\n",
    "print('EER of experimental algorithm:\\t\\t', err(e, relevance_map))\n",
    "\n",
    "print('NDCG of production algorithm:\\t\\t', ndcg(p, relevance_map))\n",
    "print('NDCG of experimental algorithm:\\t\\t', ndcg(e, relevance_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of ndcg delta for each pair where E outperforms P 0.197621474183\n",
      "Average of err delta for each pair where E outperforms P 0.26262055371067866\n",
      "Average of binary_precision delta for each pair where E outperforms P 0.306401291017\n"
     ]
    }
   ],
   "source": [
    "def delta(data, eval_function, relevance_map):\n",
    "    return [(x, y, eval_function(x, relevance_map) - eval_function(y, relevance_map))\n",
    "            for x, y in data]\n",
    "\n",
    "data = [random_sample(5) for _ in range(5000)]\n",
    "\n",
    "filtered_data = [x for x in delta(data, ndcg, relevance_map) if x[2] > 0]\n",
    "print('Average of ndcg delta for each pair where E outperforms P', \n",
    "      sum([x[2] for x in filtered_data]) / len(filtered_data))\n",
    "\n",
    "filtered_data = [x for x in delta(data, err, relevance_map) if x[2] > 0]\n",
    "print('Average of err delta for each pair where E outperforms P', \n",
    "      sum([x[2] for x in filtered_data]) / len(filtered_data))\n",
    "\n",
    "filtered_data = [x for x in delta(data, binary_precision, relevance_map) if x[2] > 0]\n",
    "print('Average of binary_precision delta for each pair where E outperforms P', \n",
    "      sum([x[2] for x in filtered_data]) / len(filtered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4} {8, 5, 6, 7}\n",
      "[0, 1, 2, 3, 4] [5, 6, 7, 8, 9]\n",
      "[0, 5, 6, 1, 7, 2, 3, 8, 4]\n"
     ]
    }
   ],
   "source": [
    "def teamdraft_interleaving(docs1, docs2):\n",
    "    team_a = set()\n",
    "    team_b = set()\n",
    "    i = []\n",
    "    \n",
    "    while len(set(docs1) - set(i)) > 0 and len(set(docs2) - set(i)):\n",
    "        if len(team_a) < len(team_b) or (len(team_a) == len(team_b) and random.random() > 0.5):\n",
    "            k = [x for x in docs1 if not x in i][0]\n",
    "            i.append(k)\n",
    "            team_a.add(k)\n",
    "        else:\n",
    "            k = [x for x in docs2 if not x in i][0]\n",
    "            i.append(k)\n",
    "            team_b.add(k)\n",
    "    return i, team_a, team_b\n",
    "\n",
    "docs1, docs2 = ['a', 'b', 'c', 'd'], ['b', 'c', 'd', 'a' ]\n",
    "p, e = random_sample(5)\n",
    "p_n = [x for x in range(len(p))]\n",
    "e_n = [x + len(p) for x in range(len(p))]\n",
    "\n",
    "i, a, b = teamdraft_interleaving(p_n, e_n)\n",
    "labels_i = [(p+e)[vis] for vis in i]\n",
    "\n",
    "print(a, b)\n",
    "print(p_n, e_n)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [5 9 1 4 7 0 3 6 8 2]\n",
      "B: [5 1 4 8 0 6 3 9 2 7]\n",
      "I: [5 1 9 4 8 0 7 6 3 2]\n",
      "S: [1 1 1 1 0 1 0 1 1 1]\n",
      "No items will contribute to the score after index 8\n",
      "A_reduced: [5 9 1 4 7 0 3 6 8]\n",
      "B_reduced: [5 1 4 8 0 6 3 9 2]\n",
      "I: [5 1 9 4 8 0 7 6 3 2]\n",
      "S: [1 1 1 0 0 1 0 0 1 1]\n",
      "No items will contribute to the score after index 8\n",
      "A_reduced: [5 9 1 4 7 0 3 6 8]\n",
      "B_reduced: [5 1 4 8 0 6 3 9 2]\n",
      "I: [5 1 9 4 8 0 7 6 3 2]\n",
      "Score of A: 12\n",
      "Score of B: 13\n"
     ]
    }
   ],
   "source": [
    "def balanced_interleaving(A, B):\n",
    "    I = []\n",
    "    pointers = []\n",
    "    k_a = 0\n",
    "    k_b = 0\n",
    "    first = random.randint(0, 1) # 0 or 1\n",
    "    \n",
    "    \n",
    "    while((k_a < len(A)) and (k_b < len(B))): # while A or B still have unseen items\n",
    "        if k_a < k_b or k_a == k_b and first:\n",
    "            if A[k_a] not in I:\n",
    "                I.append(A[k_a])\n",
    "                pointers.append('A')\n",
    "            k_a += 1 # always increase index if trying to add\n",
    "        else:\n",
    "            if B[k_b] not in I:\n",
    "                I.append(B[k_b])\n",
    "                pointers.append('B')\n",
    "            k_b += 1 # always increase index if trying to add\n",
    "            \n",
    "    return np.array(I), pointers\n",
    "        \n",
    "def determine_winner(A, B, I, sessions):\n",
    "    score_A = 0\n",
    "    score_B = 0\n",
    "    for session in sessions:\n",
    "        print(\"S:\", session)\n",
    "        clicks = np.argwhere(session == 1)\n",
    "        if clicks.any():\n",
    "            last_item = I[clicks[-1][0]]\n",
    "            playfield = priority_index(last_item, A, B) \n",
    "            print(\"No items will contribute to the score after index\", playfield)\n",
    "        else:\n",
    "            playfield = -1 # no clicks mean A and B are reduced to empty lists\n",
    "        A_reduced = A[:playfield+1]\n",
    "        B_reduced = B[:playfield+1]\n",
    "        print(\"A_reduced:\", A_reduced)\n",
    "        print(\"B_reduced:\", B_reduced)\n",
    "        print(\"I:\", I)\n",
    "\n",
    "        for index, clicked in enumerate(session):\n",
    "            if clicked:\n",
    "                if index in A_reduced:\n",
    "                    score_A += 1\n",
    "                if index in B_reduced:\n",
    "                    score_B += 1\n",
    "            \n",
    "    return score_A, score_B\n",
    "\n",
    "# Determine the line above which the items \n",
    "# of each set count towards the to be calculated score    \n",
    "def priority_index(item, A, B):\n",
    "    for index, _ in enumerate(A):\n",
    "        if item == A[index] or item == B[index]:\n",
    "            return index\n",
    "\n",
    "\n",
    "A = np.array(random.sample(range(10), 10))\n",
    "B = np.array(random.sample(range(10), 10))\n",
    "I, _ = balanced_interleaving(A, B)\n",
    "sessions = np.random.randint(2, size=(2, 10))\n",
    "print(\"A:\", A)\n",
    "print(\"B:\", B)\n",
    "print(\"I:\", I)\n",
    "score_A, score_B = determine_winner(A, B, I, sessions)\n",
    "print(\"Score of A:\", score_A)\n",
    "print(\"Score of B:\", score_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.576893042361473"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sessions from Yandex file...\n",
      "Number of sessions: 56638\n"
     ]
    }
   ],
   "source": [
    "def load_yandex(filename):\n",
    "    sessions = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        data = [line.strip().split('\\t') for  line in f.readlines()]\n",
    "    for i, query_line in enumerate(data):\n",
    "        # Q indicates start of a session\n",
    "        if query_line[2] != \"Q\":\n",
    "            continue\n",
    "\n",
    "        url_ids = query_line[5:]\n",
    "\n",
    "        # Get url_ids of all subsequent lines that are clicks\n",
    "        clicks = np.zeros(len(url_ids))\n",
    "        for click_line in data[i+1:]:\n",
    "            if click_line[2] == \"C\":\n",
    "                click_url = click_line[3]\n",
    "                if click_url not in url_ids:\n",
    "                    continue\n",
    "                clicks[url_ids.index(click_url)] = 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            sessions.append(clicks)\n",
    "    return np.vstack(sessions)\n",
    "\n",
    "print('Loading sessions from Yandex file...')\n",
    "sessions = load_yandex('YandexRelPredChallenge.txt')\n",
    "print('Number of sessions:', len(sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67452947  0.44344786  0.37036972  0.30758501  0.25986087  0.22327766\n",
      "  0.20406794  0.18409901  0.170345    0.17112186]\n",
      "0.30087044034\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def calc_rel_prob(label):\n",
    "    return 2 ** relevance_map[label] / 2 ** max(relevance_map.values())\n",
    "\n",
    "\n",
    "class PBM(object):\n",
    "    def __init__(self, ranking_size):\n",
    "        self.alpha = defaultdict(lambda: 1)\n",
    "        self.gamma = [random.random() for _ in range(ranking_size)]\n",
    "        \n",
    "    def estimate(self, S):\n",
    "        self.gamma = S.sum(axis=0) / len(S)\n",
    "    \n",
    "    def predict(self, ranking):\n",
    "        return [g * calc_rel_prob(u) for g, u in zip(self.gamma, ranking)]\n",
    "           \n",
    "    def simulate(self, ranking):\n",
    "        return np.array([1 if np.random.random() < prob else 0 for prob in self.predict(ranking)])\n",
    "\n",
    "class RCM:\n",
    "    def _init_(self):\n",
    "        self.rho = 0\n",
    "        \n",
    "    def estimate(self, S):\n",
    "        self.rho = sum(sum(s) for s in S) / sum(len(s) for s in S)\n",
    "        \n",
    "    def predict(self, ranking):\n",
    "        probs = [self.rho] * len(ranking)\n",
    "        return probs\n",
    "            \n",
    "    def simulate(self, ranking):\n",
    "        return np.array([1 if np.random.random() < prob else 0 for prob in self.predict(ranking)])\n",
    "\n",
    "pbm_model = PBM(sessions.shape[1])\n",
    "pbm_model.estimate(sessions)\n",
    "print(pbm_model.gamma)\n",
    "\n",
    "rcm_model = RCM()\n",
    "rcm_model.estimate(sessions)\n",
    "print(rcm_model.rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4975713210645139"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def experiment(model):\n",
    "    A_winners = 0\n",
    "    B_winners = 0\n",
    "\n",
    "    def one(pair):\n",
    "        I, pointers = balanced_interleaving(pair[0], pair[1])\n",
    "        winner = model.simulate(I)\n",
    "        return [pointers[i] for i in winner]\n",
    "    \n",
    "    for pair in data:\n",
    "        winners = one(pair)\n",
    "        for winner in winners:\n",
    "            A_winners += 1 if winner == 'A' else 0\n",
    "            B_winners += 1 if winner == 'B' else 0\n",
    "        \n",
    "    return B_winners / (B_winners + A_winners)\n",
    "\n",
    "\n",
    "experiment(rcm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
