{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical part\n",
    "### Theoretical part\n",
    "\n",
    "1a P(mth experiment gives significant result | m experiments lacking power to reject H0) = $$\\alpha (1-\\alpha)^{m-1}$$ <br>\n",
    "1b P(at least one significant result | m experiments lacking power to reject H0) = $$\\displaystyle \\sum_{i=1}^m \\alpha (1-\\alpha)^{i-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "Simulate Rankings of Relevance for E and P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math, random, itertools, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pairs: 59049\n",
      "first 10 pairs:\n",
      "(('N', 'N', 'N', 'N', 'N'), ('N', 'N', 'N', 'N', 'N'))\n",
      "(('N', 'N', 'N', 'N', 'N'), ('N', 'N', 'N', 'N', 'R'))\n",
      "(('N', 'N', 'N', 'N', 'N'), ('N', 'N', 'N', 'N', 'HR'))\n",
      "(('N', 'N', 'N', 'N', 'N'), ('N', 'N', 'N', 'R', 'N'))\n",
      "(('N', 'N', 'N', 'N', 'N'), ('N', 'N', 'N', 'R', 'R'))\n",
      "(('N', 'N', 'N', 'N', 'N'), ('N', 'N', 'N', 'R', 'HR'))\n",
      "(('N', 'N', 'N', 'N', 'N'), ('N', 'N', 'N', 'HR', 'N'))\n",
      "(('N', 'N', 'N', 'N', 'N'), ('N', 'N', 'N', 'HR', 'R'))\n",
      "(('N', 'N', 'N', 'N', 'N'), ('N', 'N', 'N', 'HR', 'HR'))\n",
      "(('N', 'N', 'N', 'N', 'N'), ('N', 'N', 'R', 'N', 'N'))\n"
     ]
    }
   ],
   "source": [
    "def pair_generator():\n",
    "    \"\"\"\n",
    "    A generator that returns pairs of all possible combinations \n",
    "    of [N, R, HR] of length 5.\"\"\"\n",
    "    for p in itertools.product(itertools.product(['N', 'R', 'HR'], repeat=5), repeat=2):\n",
    "        yield p\n",
    "\n",
    "def random_sample(length):\n",
    "    '''\n",
    "    Returns a sample pair that\n",
    "    consists of a production and \n",
    "    an experiment list, with as possible\n",
    "    values {N, R, HR}.\n",
    "    '''\n",
    "    values = ['N', 'R', 'HR']\n",
    "    \n",
    "    p = [values[random.randint(0, 2)] for _ in range(length)]\n",
    "    e = [values[random.randint(0, 2)] for _ in range(length)]\n",
    "    \n",
    "    return p, e\n",
    "\n",
    "print('Total number of pairs:', len(list(pair_generator())))\n",
    "print('first 10 pairs:')\n",
    "pair_gen = pair_generator()\n",
    "for _ in range(10):\n",
    "    print(next(pair_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "Implement Evaluation Measures. <br>\n",
    "Used measures: binary precision, ndcg, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement Evaluation Measures\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def binary_precision(p, f=None):\n",
    "    return np.array([0 if x == 'N' else 1 for x in p]).sum() / len(p)\n",
    "\n",
    "def ndcg(p, relevance_map):\n",
    "    dcg = np.array([\n",
    "        (2 ** relevance_map[x] - 1) / np.log2(r + 1) for r, x in enumerate(p, start=1) \n",
    "    ])\n",
    "\n",
    "    return (dcg / (max(relevance_map.values()) * len(p))).sum() if dcg.max() != 0 else 0\n",
    "\n",
    "def err(p, relevance_map):\n",
    "    P = 1\n",
    "    E = 0\n",
    "    for r, v in enumerate(p, start=1):\n",
    "        R = (2 ** relevance_map[v] - 1) / (2 ** max(relevance_map.values()))\n",
    "        E += P * R / r\n",
    "        P *= (1-R)\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of production algorithm:\t 0.4\n",
      "Precision of experimental algorithm:\t 0.4\n",
      "EER of production algorithm:\t\t 0.2\n",
      "EER of experimental algorithm:\t\t 0.3125\n",
      "NDCG of production algorithm:\t\t 0.167888248145\n",
      "NDCG of experimental algorithm:\t\t 0.213092975357\n"
     ]
    }
   ],
   "source": [
    "# Test each implemented measure on a sample datapoint\n",
    "\n",
    "p, e = random_sample(5)\n",
    "\n",
    "relevance_map = {\n",
    "    'N': 0,\n",
    "    'R': 1,\n",
    "    'HR': 2\n",
    "}\n",
    "\n",
    "print('Precision of production algorithm:\\t', binary_precision(p))\n",
    "print('Precision of experimental algorithm:\\t', binary_precision(e))\n",
    "\n",
    "print('EER of production algorithm:\\t\\t', err(p, relevance_map))\n",
    "print('EER of experimental algorithm:\\t\\t', err(e, relevance_map))\n",
    "\n",
    "print('NDCG of production algorithm:\\t\\t', ndcg(p, relevance_map))\n",
    "print('NDCG of experimental algorithm:\\t\\t', ndcg(e, relevance_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "For the three measures and all P and E ranking pairs constructed above calculate the difference: 𝛥measure = measureE-measureP. Consider only those pairs for which E outperforms P.\n",
    "\n",
    "Delta measures are calculated on 5000 random datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of ndcg delta for each pair where E outperforms P 0.19705352172\n",
      "Average of err delta for each pair where E outperforms P 0.26321904286340364\n",
      "Average of binary_precision delta for each pair where E outperforms P 0.312278761062\n"
     ]
    }
   ],
   "source": [
    "def delta(data, eval_function, relevance_map):\n",
    "    return [(x, y, eval_function(x, relevance_map) - eval_function(y, relevance_map))\n",
    "            for x, y in data]\n",
    "\n",
    "# Generate 5000 random datapoints\n",
    "data = [random_sample(5) for _ in range(5000)]\n",
    "\n",
    "data_ndcg = [x for x in delta(data, ndcg, relevance_map) if x[2] > 0]\n",
    "print('Average of ndcg delta for each pair where E outperforms P', \n",
    "      sum([x[2] for x in data_ndcg]) / len(data_ndcg))\n",
    "\n",
    "data_err = [x for x in delta(data, err, relevance_map) if x[2] > 0]\n",
    "print('Average of err delta for each pair where E outperforms P', \n",
    "      sum([x[2] for x in data_err]) / len(data_err))\n",
    "\n",
    "data_bp = [x for x in delta(data, binary_precision, relevance_map) if x[2] > 0]\n",
    "print('Average of binary_precision delta for each pair where E outperforms P', \n",
    "      sum([x[2] for x in data_bp]) / len(data_bp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "Implement Team-Draft interleaving and Balanced interleaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-ae63a5fa3213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mlabels_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "def teamdraft_interleaving(docs1, docs2):\n",
    "    team_a = set()\n",
    "    team_b = set()\n",
    "    i = []\n",
    "    \n",
    "    while len(set(docs1) - set(i)) > 0 and len(set(docs2) - set(i)):\n",
    "        if len(team_a) < len(team_b) or (len(team_a) == len(team_b) and random.random() > 0.5):\n",
    "            k = [x for x in docs1 if not x in i][0]\n",
    "            i.append(k)\n",
    "            team_a.add(k)\n",
    "        else:\n",
    "            k = [x for x in docs2 if not x in i][0]\n",
    "            i.append(k)\n",
    "            team_b.add(k)\n",
    "    return i, team_a, team_b\n",
    "\n",
    "docs1, docs2 = ['a', 'b', 'c', 'd'], ['b', 'c', 'd', 'a' ]\n",
    "p, e = random_sample(5)\n",
    "p_n = [x for x in range(len(p))]\n",
    "e_n = [x + len(p) for x in range(len(p))]\n",
    "\n",
    "I, A, B = teamdraft_interleaving(p_n, e_n)\n",
    "labels_i = [(p+e)[i] for i in I]\n",
    "\n",
    "print(a, b)\n",
    "print(p_n, e_n)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [5 9 1 4 7 0 3 6 8 2]\n",
      "B: [5 1 4 8 0 6 3 9 2 7]\n",
      "I: [5 1 9 4 8 0 7 6 3 2]\n",
      "S: [1 1 1 1 0 1 0 1 1 1]\n",
      "No items will contribute to the score after index 8\n",
      "A_reduced: [5 9 1 4 7 0 3 6 8]\n",
      "B_reduced: [5 1 4 8 0 6 3 9 2]\n",
      "I: [5 1 9 4 8 0 7 6 3 2]\n",
      "S: [1 1 1 0 0 1 0 0 1 1]\n",
      "No items will contribute to the score after index 8\n",
      "A_reduced: [5 9 1 4 7 0 3 6 8]\n",
      "B_reduced: [5 1 4 8 0 6 3 9 2]\n",
      "I: [5 1 9 4 8 0 7 6 3 2]\n",
      "Score of A: 12\n",
      "Score of B: 13\n"
     ]
    }
   ],
   "source": [
    "def balanced_interleaving(A, B):\n",
    "    I = []\n",
    "    pointers = []\n",
    "    k_a = 0\n",
    "    k_b = 0\n",
    "    first = random.randint(0, 1) # 0 or 1\n",
    "    \n",
    "    \n",
    "    while((k_a < len(A)) and (k_b < len(B))): # while A or B still have unseen items\n",
    "        if k_a < k_b or k_a == k_b and first:\n",
    "            if A[k_a] not in I:\n",
    "                I.append(A[k_a])\n",
    "                pointers.append('A')\n",
    "            k_a += 1 # always increase index if trying to add\n",
    "        else:\n",
    "            if B[k_b] not in I:\n",
    "                I.append(B[k_b])\n",
    "                pointers.append('B')\n",
    "            k_b += 1 # always increase index if trying to add\n",
    "            \n",
    "    return np.array(I), pointers\n",
    "        \n",
    "def determine_winner(A, B, I, sessions):\n",
    "    score_A = 0\n",
    "    score_B = 0\n",
    "    for session in sessions:\n",
    "        print(\"S:\", session)\n",
    "        clicks = np.argwhere(session == 1)\n",
    "        if clicks.any():\n",
    "            last_item = I[clicks[-1][0]]\n",
    "            playfield = priority_index(last_item, A, B) \n",
    "            print(\"No items will contribute to the score after index\", playfield)\n",
    "        else:\n",
    "            playfield = -1 # no clicks mean A and B are reduced to empty lists\n",
    "        A_reduced = A[:playfield+1]\n",
    "        B_reduced = B[:playfield+1]\n",
    "        print(\"A_reduced:\", A_reduced)\n",
    "        print(\"B_reduced:\", B_reduced)\n",
    "        print(\"I:\", I)\n",
    "\n",
    "        for index, clicked in enumerate(session):\n",
    "            if clicked:\n",
    "                if index in A_reduced:\n",
    "                    score_A += 1\n",
    "                if index in B_reduced:\n",
    "                    score_B += 1\n",
    "            \n",
    "    return score_A, score_B\n",
    "\n",
    "# Determine the line above which the items \n",
    "# of each set count towards the to be calculated score    \n",
    "def priority_index(item, A, B):\n",
    "    for index, _ in enumerate(A):\n",
    "        if item == A[index] or item == B[index]:\n",
    "            return index\n",
    "\n",
    "\n",
    "A = np.array(random.sample(range(10), 10))\n",
    "B = np.array(random.sample(range(10), 10))\n",
    "I, _ = balanced_interleaving(A, B)\n",
    "sessions = np.random.randint(2, size=(2, 10))\n",
    "print(\"A:\", A)\n",
    "print(\"B:\", B)\n",
    "print(\"I:\", I)\n",
    "score_A, score_B = determine_winner(A, B, I, sessions)\n",
    "print(\"Score of A:\", score_A)\n",
    "print(\"Score of B:\", score_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "Implement User Clicks Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sessions from Yandex file...\n",
      "Number of sessions: 42652\n"
     ]
    }
   ],
   "source": [
    "# To estimate clickmdel parameters, the provided Yandex file is used\n",
    "\n",
    "def load_yandex(filename):\n",
    "    sessions = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        data = [line.strip().split('\\t') for  line in f.readlines()]\n",
    "    for i, query_line in enumerate(data):\n",
    "        # Q indicates start of a session\n",
    "        if query_line[2] == \"Q\":\n",
    "            url_ids = query_line[5:]\n",
    "            \n",
    "            # Get url_ids of all subsequent lines that are clicks\n",
    "            clicks = np.zeros(len(url_ids))\n",
    "            for click_line in data[i+1:]:\n",
    "                if click_line[2] == \"C\":\n",
    "                    click_url = click_line[3]\n",
    "                    if click_url not in url_ids:\n",
    "                        continue\n",
    "                    clicks[url_ids.index(click_url)] = 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            sessions.append(clicks)\n",
    "    return np.vstack(sessions)\n",
    "\n",
    "print('Loading sessions from Yandex file...')\n",
    "sessions = load_yandex('YandexRelPredChallenge.txt')\n",
    "print('Number of sessions:', len(sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCM parameters\n",
      "rho = 0.125025790115\n",
      "\n",
      "PBM parameters\n",
      "gamma = [ 0.45006096  0.1950905   0.13931351  0.10569258  0.08184845  0.06712464\n",
      "  0.05936416  0.05296352  0.04808684  0.05071275]\n"
     ]
    }
   ],
   "source": [
    "# Implement PBM and RCM\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def calc_alpha(label):\n",
    "    return 2 ** relevance_map[label] / 2 ** max(relevance_map.values())\n",
    "\n",
    "\n",
    "class PBM(object):\n",
    "    def __init__(self, ranking_size):\n",
    "        self.alpha = defaultdict(lambda: 1)\n",
    "        self.gamma = [random.random() for _ in range(ranking_size)]\n",
    "        \n",
    "    def estimate(self, S):\n",
    "        \"\"\"Estimate parameters of the model.\"\"\"\n",
    "        self.gamma = S.sum(axis=0) / len(S)\n",
    "    \n",
    "    def predict(self, ranking):\n",
    "        \"\"\"Predict click probabilities of a given session.\"\"\"\n",
    "        return [g * calc_alpha(u) for g, u in zip(self.gamma, ranking)]\n",
    "           \n",
    "    def simulate(self, ranking):\n",
    "        \"\"\"Simulate clicks on a given session.\"\"\"\n",
    "        return np.array([1 if np.random.random() < prob else 0 for prob in self.predict(ranking)])\n",
    "\n",
    "class RCM:\n",
    "    def _init_(self):\n",
    "        self.rho = 0\n",
    "        \n",
    "    def estimate(self, S):\n",
    "        \"\"\"Estimate parameters of the model.\"\"\"\n",
    "        self.rho = np.sum(S) / S.size\n",
    "        \n",
    "    def predict(self, ranking):\n",
    "        \"\"\"Predict click probabilities of a given session.\"\"\"\n",
    "        probs = [self.rho] * len(ranking)\n",
    "        return probs\n",
    "            \n",
    "    def simulate(self, ranking):\n",
    "        \"\"\"Simulate clicks on a given session.\"\"\"\n",
    "        return np.array([1 if np.random.random() < prob else 0 for prob in self.predict(ranking)])\n",
    "\n",
    "print('RCM parameters')\n",
    "rcm_model = RCM()\n",
    "rcm_model.estimate(sessions)\n",
    "print('rho =', rcm_model.rho)\n",
    "print()\n",
    "\n",
    "print('PBM parameters')\n",
    "pbm_model = PBM(sessions.shape[1])\n",
    "pbm_model.estimate(sessions)\n",
    "print('gamma =', pbm_model.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_interleaving(data, N, clickmodel, interleaver, interleave_scorer):\n",
    "    winners = []\n",
    "    for A, B in data:\n",
    "        I = interleaver(A, B)\n",
    "        for i in range(N):\n",
    "            session = clickmodel.simulate(I)\n",
    "            winners.append(interleave_scorer(A, B, I, session))\n",
    "    return winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
